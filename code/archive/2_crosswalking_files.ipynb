{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import census\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files\n",
    "\n",
    "Most of the input files are located on google drive and . I suggest downloading [Google's Drive File Stream](https://support.google.com/a/answer/7491144?utm_medium=et&utm_source=aboutdrive&utm_content=getstarted&utm_campaign=en_us) app, which doesn't download all Google Drive items to your computer, but rather pulls them as necessary. This will save a lot of space but compromises speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files\n",
    "# If reproducing for a new city, change to that city name here\n",
    "city_name = 'Memphis'\n",
    "\n",
    "# Google File Drive Stream pathway for a mac. \n",
    "input_path = '/Volumes/GoogleDrive/My Drive/CCI Docs/Current Projects/SPARCC/Data/Inputs/'\n",
    "output_path = '~/git/sparcc/data/'\n",
    "\n",
    "census_90 = pd.read_csv(output_path+city_name+'census_90.csv', index_col = 0)\n",
    "census_00 = pd.read_csv(output_path+city_name+'census_00.csv', index_col = 0)\n",
    "\n",
    "# Crosswalk files\n",
    "xwalk_90_10 = pd.read_csv(input_path+'crosswalk_1990_2010.csv')\n",
    "xwalk_00_10 = pd.read_csv(input_path+'crosswalk_2000_2010.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose city and census tracts of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add elif for your city here\n",
    "\n",
    "if city_name == 'Chicago':\n",
    "    state = '17'\n",
    "    FIPS = ['031', '043', '089', '093', '097', '111', '197']\n",
    "\n",
    "elif city_name == 'Atlanta':\n",
    "    state = '13'\n",
    "    FIPS = ['057', '063', '067', '089', '097', '113', '121', '135', '151', '247']\n",
    "# add an LA elif    \n",
    "elif city_name == 'Denver':\n",
    "    state = '08'\n",
    "    FIPS = ['001', '005', '013', '014', '019', '031', '035', '047', '059']\n",
    "    \n",
    "elif city_name == 'Memphis':\n",
    "    state = ['28', '47']\n",
    "    FIPS = {'28':['033', '093'], '47': ['047', '157']}\n",
    "    \n",
    "elif city_name == 'Los Angeles':\n",
    "    state = '06'\n",
    "    FIPS = ['037']\n",
    "\n",
    "else:\n",
    "    print ('There is no information for the selected city')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates filter function\n",
    "Note - Memphis is different bc it's located in 2 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_FIPS(df):\n",
    "    if city_name != 'Memphis':\n",
    "        df = df[df['county'].isin(FIPS)].reset_index(drop = True)\n",
    "\n",
    "    else:\n",
    "        fips_list = []\n",
    "        for i in state:\n",
    "            county = FIPS[i]\n",
    "            a = list((df['FIPS'][(df['county'].isin(county))&(df['state']==i)]))\n",
    "            fips_list = fips_list + a\n",
    "        df = df[df['FIPS'].isin(fips_list)].reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates crosswalking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosswalk_files (df, xwalk, counts, medians, df_fips_base, xwalk_fips_base, xwalk_fips_horizon):\n",
    "\n",
    "    # merge dataframe with xwalk file\n",
    "    df_merge = df.merge(xwalk[['weight', xwalk_fips_base, xwalk_fips_horizon]], left_on = df_fips_base, right_on = xwalk_fips_base, how='left')                             \n",
    "\n",
    "    df = df_merge\n",
    "    \n",
    "    # apply interpolation weight\n",
    "    new_var_list = list(counts)+(medians)\n",
    "    for var in new_var_list:\n",
    "        df[var] = df[var]*df['weight']\n",
    "\n",
    "    # aggregate by horizon census tracts fips\n",
    "    df = df.groupby(xwalk_fips_horizon).sum().reset_index()\n",
    "    \n",
    "    # rename trtid10 to FIPS & FIPS to trtid_base\n",
    "    df = df.rename(columns = {'FIPS':'trtid_base',\n",
    "                              'trtid10':'FIPS'})\n",
    "    \n",
    "    # fix state, county and fips code\n",
    "    df ['state'] = df['FIPS'].astype('int64').astype(str).str.zfill(11).str[0:2]\n",
    "    df ['county'] = df['FIPS'].astype('int64').astype(str).str.zfill(11).str[2:5]\n",
    "    df ['tract'] = df['FIPS'].astype('int64').astype(str).str.zfill(11).str[5:]\n",
    "    \n",
    "    # drop weight column\n",
    "    df = df.drop(columns = ['weight'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crosswalking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1990 Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = census_90.columns.drop(['county', 'state', 'tract', 'mrent_90', 'mhval_90', 'hinc_90', 'FIPS'])\n",
    "medians = ['mrent_90', 'mhval_90', 'hinc_90']\n",
    "df_fips_base = 'FIPS'\n",
    "xwalk_fips_base = 'trtid90'\n",
    "xwalk_fips_horizon = 'trtid10'\n",
    "census_90_xwalked = crosswalk_files (census_90, xwalk_90_10,  counts, medians, df_fips_base, xwalk_fips_base, xwalk_fips_horizon )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2000 Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = census_00.columns.drop(['county', 'state', 'tract', 'mrent_00', 'mhval_00', 'hinc_00', 'FIPS'])\n",
    "medians = ['mrent_00', 'mhval_00', 'hinc_00']\n",
    "df_fips_base = 'FIPS'\n",
    "xwalk_fips_base = 'trtid00'\n",
    "xwalk_fips_horizon = 'trtid10'\n",
    "census_00_xwalked = crosswalk_files (census_00, xwalk_00_10,  counts, medians, df_fips_base, xwalk_fips_base, xwalk_fips_horizon )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Filters and exports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_90_filtered = filter_FIPS(census_90_xwalked)\n",
    "census_00_filtered = filter_FIPS(census_00_xwalked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_90_filtered.to_csv('~/git/sparcc/data/'+city_name+'census_90_10.csv')\n",
    "census_00_filtered.to_csv('~/git/sparcc/data/'+city_name+'census_00_10.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
